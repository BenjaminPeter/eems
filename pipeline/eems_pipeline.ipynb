{
 "metadata": {
  "name": "",
  "signature": "sha256:b72926ec4b0015ab484a89b173c37c876c1b886ee6397dfe757d45c5cc40d6a8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import os, sys\n",
      "import matplotlib.pyplot as plt\n",
      "pd.set_option( 'display.max_rows', 4 )\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The autoreload extension is already loaded. To reload it, use:\n",
        "  %reload_ext autoreload\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "EEMS pipeline"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Introduction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is draft of a pipeline with the goal to simplify running an eems analysis. The goal is to get to a state where you have to change parameters and then have to press enter a few times to get from raw data files to publication-ready figures.\n",
      "\n",
      "We need to do the following steps:\n",
      "1. read non-genetic data (locations, population id, individuals to retain)\n",
      "2. read genetic data (different formats)\n",
      " - vcf (current draft)\n",
      " - ms (todo)\n",
      " - bed (todo)\n",
      " - pairwise sfs (todo)\n",
      " - others ...\n",
      "3. calculate distance matrix\n",
      "4. run eems\n",
      " - locally, using octave (current draft)\n",
      " - on cluster, using matlab (todo)\n",
      "5. plot things in R\n",
      "\n",
      "One potential issue is that these scripts are partly written in different languages; eems is written in matlab, plots are in R. IPython notebooks do have some R integration, but it is unclear on how well that works with analyses that require a high throughput of data sets (i.e. simulation studies)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Define files and options"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The files we are using are: the location file, the sample file and the genetic data file. The location and sample files are simple text table with headers; the relevant columns are inferred from the headers. The current implementation picks the first matching header as the relevant one.\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Location data file"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The main purpose of this file, is to provide the spatial location of each sampled individual. The three required fiels are:\n",
      "- **population name**, a name of a population that needs to be present in the sample file\n",
      "- **latitude**, sampling coordinate\n",
      "- **longitude**, sampling coordinate\n",
      "\n",
      "The relevant headers are:\n",
      "\n",
      "`allowed_pop_names = [ 'ID', 'POP_ID', 'POP_NAME', 'POP_ORIG', 'POPULATION', 'ECOTYPE_ID' ]\n",
      "\n",
      "`allowed_lat_names = [ 'LAT', 'LATITUDE', 'Y' ]\n",
      "\n",
      "`allowed_long_names = [ 'LONG', 'LONGITUDE', 'X' ]\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#the data_file contains the genetic data\n",
      "data_type = \"vcf\" #one of bed, vcf, ms sfs (only vcf is implemented right now)\n",
      "data_file =  \"/home/peterb/carlia/files/camaxMerged.filt.inc.recode.vcf\"\n",
      "\n",
      "#the location file contains coordinates for each population\n",
      "location_file = \"/home/peterb/carlia/files/camax_coordinates.csv\"\n",
      "\n",
      "#the sample file contains the mapping between population and individuals\n",
      "sample_file = \"/home/peterb/carlia/files/sample.list\"\n",
      "\n",
      "\n",
      "\n",
      "#a temporary wormtable file needs to be created for fast vcf analysis\n",
      "temporary_wt_file = 'tmp.wt'\n",
      "\n",
      "##options for eems\n",
      "#TODO: full options list\n",
      "options = {\n",
      "    'executable'   : 'octave', #the program to run\n",
      "    'function'     : 'MCMC_diploid', #the matlab function to be called. Either MCMC_diploid or MCMC_haploid\n",
      "\n",
      "    'dir'          : '..', #the basedir of the scripts. If this nb stays in python-pipeline, it's simply ..\n",
      "    'tmp_dir'      : '../analyses/carlia' , #directory where temporary files live\n",
      "    'input_files'  : 'input/carlia', #the name of the eems INPUT files to be generated\n",
      "    'output_files' : 'output/carlia', #the name and location of the eems OUTPUT files and \n",
      "\n",
      "    'n_demes'      : ( 20, 16 ),  #the number of demes in x and y axes\n",
      "    'space_add'    : ( 0.1, 0.1), #the percentage to add to the eems range over the sample range\n",
      "               \n",
      "    'run_eems'     : True #if eems should actually be run\n",
      "                    }\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "the first thing I need to do is to load the coordinates data base. They should have a bunch of columns, many we wont need, but the important ones are <b>latitude</b>, <b>longitude</b>, and <b>pop_id</b>. As they are expected to be different between different dicts, I'll get their names from a dictionary."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load_location_file(location_file, sep=\",\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>POP</th>\n",
        "      <th>LAT</th>\n",
        "      <th>LONG</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td> CA044</td>\n",
        "      <td>-17.466667</td>\n",
        "      <td> 138.333333</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td> CA045</td>\n",
        "      <td>-16.666667</td>\n",
        "      <td> 135.850000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>40</th>\n",
        "      <td> CA097</td>\n",
        "      <td>-12.581389</td>\n",
        "      <td> 134.308056</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>41</th>\n",
        "      <td> CA100</td>\n",
        "      <td>-12.050000</td>\n",
        "      <td> 134.216667</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>42 rows \u00d7 3 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 103,
       "text": [
        "      POP        LAT        LONG\n",
        "0   CA044 -17.466667  138.333333\n",
        "1   CA045 -16.666667  135.850000\n",
        "..    ...        ...         ...\n",
        "40  CA097 -12.581389  134.308056\n",
        "41  CA100 -12.050000  134.216667\n",
        "\n",
        "[42 rows x 3 columns]"
       ]
      }
     ],
     "prompt_number": 103
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "The next function loads the sample file. This file handles the attribution of sample ids to populations.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load_sample_file( sample_file, sep=\",\" )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>IND</th>\n",
        "      <th>POP</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td> CA001</td>\n",
        "      <td> CA001</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td> CA002</td>\n",
        "      <td> CA002</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>45</th>\n",
        "      <td> CA097</td>\n",
        "      <td> CA097</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>46</th>\n",
        "      <td> CA100</td>\n",
        "      <td> CA100</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>47 rows \u00d7 2 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 104,
       "text": [
        "      IND    POP\n",
        "0   CA001  CA001\n",
        "1   CA002  CA002\n",
        "..    ...    ...\n",
        "45  CA097  CA097\n",
        "46  CA100  CA100\n",
        "\n",
        "[47 rows x 2 columns]"
       ]
      }
     ],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "location_data = load_location_file( location_file, sep=\",\" )\n",
      "sample_data = load_sample_file( sample_file, sep=\",\" )\n",
      "\n",
      "merged_data = pd.merge(location_data, sample_data)\n",
      "merged_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>POP</th>\n",
        "      <th>LAT</th>\n",
        "      <th>LONG</th>\n",
        "      <th>IND</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td> CA044</td>\n",
        "      <td>-17.466667</td>\n",
        "      <td> 138.333333</td>\n",
        "      <td> CA044</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td> CA045</td>\n",
        "      <td>-16.666667</td>\n",
        "      <td> 135.850000</td>\n",
        "      <td> CA045</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>40</th>\n",
        "      <td> CA097</td>\n",
        "      <td>-12.581389</td>\n",
        "      <td> 134.308056</td>\n",
        "      <td> CA097</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>41</th>\n",
        "      <td> CA100</td>\n",
        "      <td>-12.050000</td>\n",
        "      <td> 134.216667</td>\n",
        "      <td> CA100</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>42 rows \u00d7 4 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 105,
       "text": [
        "      POP        LAT        LONG    IND\n",
        "0   CA044 -17.466667  138.333333  CA044\n",
        "1   CA045 -16.666667  135.850000  CA045\n",
        "..    ...        ...         ...    ...\n",
        "40  CA097 -12.581389  134.308056  CA097\n",
        "41  CA100 -12.050000  134.216667  CA100\n",
        "\n",
        "[42 rows x 4 columns]"
       ]
      }
     ],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "min(merged_data['LONG']), max(merged_data['LONG'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 106,
       "text": [
        "(123.75, 139.78555600000001)"
       ]
      }
     ],
     "prompt_number": 106
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Load VCF"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The last file to load is the vcf file with the actual data. We use wormtable"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vcf2wt( data_file, temporary_wt_file )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pw_dist, n_samp_snp = get_pw_dist(temporary_wt_file, \n",
      "                                  individuals=merged_data['IND'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "10000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "20000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "30000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "40000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "50000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "60000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At this point we have all the data we need for eems to run: the vcf can be made from the pw dist matrix, the "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def write_eems_input_files( location_data, pw_dist, n_samp_snp,\n",
      "        options):\n",
      "    \"\"\"writes the eems input files.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "\n",
      "    location_data : array_like, with headers 'LAT' and 'LONG'\n",
      "        the data object with `n` locations\n",
      "    pw_dist : array_like, `n` x `n` matrix\n",
      "        the pairwise distance matrix used by eems\n",
      "    n_samp_snp : tuple (int, int)\n",
      "        tuple with the number of samples and the number of snp\n",
      "    options : dict[str] => var \n",
      "        tuple with the number of samples and the number of snp\n",
      "    \"\"\"\n",
      "    \n",
      "\n",
      "    #make directories\n",
      "    input_file = options['tmp_dir'] + os.path.sep + options['input_files']\n",
      "    output_file = options['tmp_dir'] + os.path.sep + options['output_files']\n",
      "    \n",
      "    input_dir = os.path.dirname( input_file ) \n",
      "    output_dir = os.path.dirname( output_file ) \n",
      "    \n",
      "    if not os.path.exists( input_dir ):\n",
      "        os.makedirs(  os.path.dirname( input_file )  )\n",
      "    else:\n",
      "        print (\"WARNING: input directory  %s exists, consider making a new folder\"%input_dir, file=sys.stderr )\n",
      "        \n",
      "    if not os.path.exists( output_dir ):\n",
      "        os.makedirs(  os.path.dirname( output_file ))\n",
      "    else:\n",
      "        print (\"WARNING: output directory %s exists, consider making a new folder\"%input_dir, file=sys.stderr )\n",
      "\n",
      "    \n",
      "    np.savetxt( input_file + '.diffs', pw_dist )\n",
      "    \n",
      "    \n",
      "    location_data.to_csv(input_file +'.coord', sep=' ', header=False, columns=['LONG',\n",
      "        'LAT'], index=False)\n",
      "    \n",
      "    \n",
      "    def get_inference_area_limits( options ):\n",
      "        long_pc, lat_pc = options['space_add']\n",
      "        long_d, lat_d = location_data['LONG'], location_data['LAT']\n",
      "\n",
      "        #the absolute amount to be added\n",
      "        long_add = ( max( long_d ) - min( long_d ) ) * long_pc\n",
      "        lat_add = ( max( lat_d ) - min( lat_d ) ) * lat_pc\n",
      "\n",
      "        long_limits = min( long_d ) - long_add,   max( long_d ) + long_add\n",
      "        lat_limits  = min( lat_d  ) - lat_add ,   max( lat_d  ) + lat_add\n",
      "        \n",
      "        return long_limits, lat_limits\n",
      "\n",
      "    long_limits, lat_limits = get_inference_area_limits( options )\n",
      "    \n",
      "\n",
      "    with open( input_file + '.dimns', 'w' ) as settings_file:\n",
      "        settings_file.write( \"%f %f\\n\"%( long_limits ) )\n",
      "        settings_file.write( \"%f %f\\n\"%( lat_limits ) )\n",
      "        settings_file.write( \"%f %f\\n\"%( n_samp_snp ) )\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "write_eems_input_files( location_data=merged_data, \n",
      "                        pw_dist=pw_dist,\n",
      "                        n_samp_snp= n_samp_snp,\n",
      "                        options=options)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING: input directory  ../analyses/carlia/input exists, consider making a new folder\n",
        "WARNING: output directory ../analyses/carlia/input exists, consider making a new folder\n"
       ]
      }
     ],
     "prompt_number": 94
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Running EEMS"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We should now have all the input files in the eems format. EEMS is run using a command line like this:\n",
      "\n",
      "`MCMC_diploid('..','../examples/data/uniform-schemeX-nIndiv300-s12x8-u4Nm1-L3000', 'opt', 12, 8)`\n",
      "\n",
      "for octave, the whole thing is even messier, as we first need to load the script, resulting in a command like:\n",
      "` octave --eval \"run('../mscripts/MCMC_diploid.m'); MCMC_diploid('..', 'test', 'eems_opt', 12, 8)\"`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_eems( options ):\n",
      "    \"\"\" runs eems using the octave syntax\n",
      "    \"\"\"\n",
      "    if options['executable'] == 'octave':\n",
      "        prefix = \"octave --eval \\\"run('%s/mscripts/%s.m'); \"%(options['dir'], options['function'])\n",
      "    else:\n",
      "        raise NotImplementedError\n",
      "        \n",
      "  \n",
      "    \n",
      "    eems_values = ( prefix,\n",
      "               options['function'],\n",
      "               options['dir'],\n",
      "               options['tmp_dir'] + os.path.sep + options['input_files'],\n",
      "               options['tmp_dir'] + os.path.sep +  options['output_files'],\n",
      "               options['n_demes'][0],\n",
      "               options['n_demes'][1],)\n",
      "    eems_command = \"%s %s('%s', '%s', '%s', %d, %d)\\\" \"%eems_values\n",
      "    \n",
      "    if options['run_eems']:\n",
      "        print( eems_command )\n",
      "        os.system( eems_command )\n",
      "    else:\n",
      "        print( eems_command )\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "run_eems( options )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "octave --eval \"run('../mscripts/MCMC_diploid.m');  MCMC_diploid('..', '../analyses/carlia/input/carlia', '../analyses/carlia/output/carlia', 20, 16)\" \n"
       ]
      }
     ],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "os.makedirs?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    }
   ],
   "metadata": {}
  }
 ]
}