{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from glu.lib.seqlib import vcf #VCF parser from https://code.google.com/p/glu-genetics/source/browse/glu/lib/seqlib/vcf.py\n",
      "import vcfnp\n",
      "pd.set_option( 'display.max_rows', 10 )\n",
      "from multiprocessing import Pool"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "EEMS pipeline"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Introduction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The goal of this Notebook is to generate an pipeline for the EEMS package. Ideally, it will start of with the raw genotype files, (vcf, bed, ms, ...), a coordinate file and some settings type file, and produce EEMS figures. The main idea is to do the following steps:\n",
      "<ol>\n",
      "<li>reading file with sample names to retain, using filters</li>\n",
      "<li>data structure linking sample names to physical loctions</li>\n",
      "<li>reading data, filtering</li>\n",
      "<li>get pw distance matrix</li>\n",
      "<li>run eems</li>\n",
      "<li>plot things in R</li>\n",
      "</ol>\n",
      "\n",
      "One potential issue is that these scripts are partly written in different languages; eems is written in matlab, plots are in R. Not sure at this stage whether to port stuff or simply write wrappers..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The parameters are hopefully pretty self explanatory:\n",
      "data file is the file with the genetic data in either ms, vcf or bed\n",
      "location is the file with location info, \n",
      "sample is the file that states which samples should be used.\n",
      "\n",
      "Note: if I wanna run simulations, I really should set up a CLI for that."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_dir = \"./\"\n",
      "data_type = \"ms\" #one of bed, vcf, ms\n",
      "data_file = \"example.ms\"\n",
      "\n",
      "location_dir = \"./\"\n",
      "location_file = \"example.loc\"\n",
      "\n",
      "sample_dir = \"./\"\n",
      "sample_file = \"example.smp\"\n",
      "\n",
      "\n",
      "#options for eems, to be set up\n",
      "eems_options = dict(\n",
      "                    \n",
      "                    )\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_file = \"/home/peterb/carlia/files/camaxMerged.filt.inc.recode.vcf\"\n",
      "location_file = \"/home/peterb/carlia/files/camax_coordinates.csv\"\n",
      "sample_file = \"/home/peterb/carlia/files/sample.list\"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "the first thing I need to do is to load the coordinates data base. They should have a bunch of columns, many we wont need, but the important ones are <b>latitude</b>, <b>longitude</b>, and <b>pop_id</b>. As they are expected to be different between different dicts, I'll get their names from a dictionary."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_location_file( location_file, location_dir=\"./\", **keywords ):\n",
      "    \"\"\" this function loads the location data using lat, long and pop_id. \n",
      "        The approach here is that I'll draw them from a list of possible ids,\n",
      "        but the resulting data frame will always have three cols named POP, LAT, LONG.\n",
      "    \"\"\"\n",
      "    location_data = pd.read_table( location_file, **keywords)\n",
      "    header = location_data.columns.values\n",
      "    \n",
      "    #possible ids for population, possibly add more depending on what people come up with\n",
      "    allowed_pop_names = [ 'ID', 'POP_ID', 'POP_NAME', 'POP_ORIG', 'POPULATION', 'ECOTYPE_ID' ] \n",
      "    \n",
      "    #possible ids for latitude & longitude\n",
      "    allowed_lat_names = [ 'LAT', 'LATITUDE', 'Y' ]\n",
      "    allowed_long_names = [ 'LONG', 'LONGITUDE', 'X' ]    \n",
      "    \n",
      "    def get_first_id( header, allowed_names):\n",
      "        \"\"\"private function that gets the first match from the possible list of matches\"\"\"\n",
      "        for name in allowed_names:\n",
      "            for i, h in enumerate( header ):\n",
      "                if name.upper() == h.upper():\n",
      "                    return h\n",
      "        raise ValueError('did not find correct header for %s.\\\n",
      "                         Please adjust file/ script'%allowed_names)\n",
      "    \n",
      "    POP = get_first_id( header, allowed_pop_names )\n",
      "    LAT = get_first_id( header, allowed_lat_names )\n",
      "    LONG = get_first_id( header, allowed_long_names )\n",
      "\n",
      "    location_data = location_data[ [POP, LAT, LONG] ]\n",
      "    location_data.columns = [ 'POP', 'LAT', 'LONG' ]\n",
      "    \n",
      "    return location_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load_location_file(location_file, sep=\",\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>POP</th>\n",
        "      <th>LAT</th>\n",
        "      <th>LONG</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> CA044</td>\n",
        "      <td>-17.466667</td>\n",
        "      <td> 138.333333</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> CA045</td>\n",
        "      <td>-16.666667</td>\n",
        "      <td> 135.850000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> CA046</td>\n",
        "      <td>-16.450000</td>\n",
        "      <td> 134.616667</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> CA047</td>\n",
        "      <td>-12.700000</td>\n",
        "      <td> 132.933333</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> CA048</td>\n",
        "      <td>-20.775000</td>\n",
        "      <td> 139.785556</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td> CA049</td>\n",
        "      <td>-14.025117</td>\n",
        "      <td> 130.770517</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td> CA050</td>\n",
        "      <td>-15.875286</td>\n",
        "      <td> 129.051271</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td> CA051</td>\n",
        "      <td>-13.790000</td>\n",
        "      <td> 133.090000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td> CA052</td>\n",
        "      <td>-12.720000</td>\n",
        "      <td> 131.702167</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td> CA053</td>\n",
        "      <td>-14.800000</td>\n",
        "      <td> 134.945000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th></th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>42 rows \u00d7 3 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "     POP        LAT        LONG\n",
        "0  CA044 -17.466667  138.333333\n",
        "1  CA045 -16.666667  135.850000\n",
        "2  CA046 -16.450000  134.616667\n",
        "3  CA047 -12.700000  132.933333\n",
        "4  CA048 -20.775000  139.785556\n",
        "5  CA049 -14.025117  130.770517\n",
        "6  CA050 -15.875286  129.051271\n",
        "7  CA051 -13.790000  133.090000\n",
        "8  CA052 -12.720000  131.702167\n",
        "9  CA053 -14.800000  134.945000\n",
        "     ...        ...         ...\n",
        "\n",
        "[42 rows x 3 columns]"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The next function loads the sample file. This file handles the attribution of sample ids to populations."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_sample_file( location_file, location_dir=\"./\", **kwargs):\n",
      "    \"\"\" \n",
      "    this file loads the sample ids that are used when analyzing VCF/bed files\n",
      "    \"\"\"\n",
      "    sample_data = pd.read_table( sample_file, **kwargs )\n",
      "    header = sample_data.columns.values\n",
      "    \n",
      "    #possible ids for population, possibly add more depending on what people come up with\n",
      "    allowed_pop_names = [ 'POP_ID', 'POP_NAME', 'POP_ORIG', 'POPULATION', 'SIMPLE_MAJORITY', 'SAMPLE' ] \n",
      "    \n",
      "    #possible ids for individuals & families (optional)\n",
      "    allowed_ind_names = [ 'IID', 'IND', 'INDIVIDUAL', 'INDIVIDUALS', 'ID', 'SAMPLE' ]\n",
      "    allowed_family_names = [ 'FID', 'FAM', 'FAMILY', 'FAMILIES' ]    \n",
      "    \n",
      "    def get_first_id( header, allowed_names):\n",
      "        \"\"\"private function that gets the first match from the possible list of matches\"\"\"\n",
      "        for name in allowed_names:\n",
      "            for i, h in enumerate( header ):\n",
      "                if name.upper() == h.upper():\n",
      "                    return h\n",
      "        raise ValueError('did not find correct header for %s.\\\n",
      "                         Please adjust file/ script'%allowed_names)\n",
      "    \n",
      "    POP = get_first_id( header, allowed_pop_names )\n",
      "    IND = get_first_id( header, allowed_ind_names )\n",
      "    #FAMILY = get_first_id( header, allowed_family_names )\n",
      "\n",
      "    sample_data = sample_data[ [IND, POP] ]\n",
      "    sample_data.columns = [ 'IND', 'POP' ]\n",
      "\n",
      "\n",
      "    return sample_data\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load_sample_file( sample_file, sep=\",\" )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>IND</th>\n",
        "      <th>POP</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> CA001</td>\n",
        "      <td> CA001</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> CA002</td>\n",
        "      <td> CA002</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> CA043</td>\n",
        "      <td> CA043</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> CA071</td>\n",
        "      <td> CA071</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> CA077</td>\n",
        "      <td> CA077</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td> CA044</td>\n",
        "      <td> CA044</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td> CA045</td>\n",
        "      <td> CA045</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td> CA046</td>\n",
        "      <td> CA046</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td> CA047</td>\n",
        "      <td> CA047</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td> CA048</td>\n",
        "      <td> CA048</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th></th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>47 rows \u00d7 2 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "     IND    POP\n",
        "0  CA001  CA001\n",
        "1  CA002  CA002\n",
        "2  CA043  CA043\n",
        "3  CA071  CA071\n",
        "4  CA077  CA077\n",
        "5  CA044  CA044\n",
        "6  CA045  CA045\n",
        "7  CA046  CA046\n",
        "8  CA047  CA047\n",
        "9  CA048  CA048\n",
        "     ...    ...\n",
        "\n",
        "[47 rows x 2 columns]"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "location_data = load_location_file( location_file, sep=\",\" )\n",
      "sample_data = load_sample_file( sample_file, sep=\",\" )\n",
      "\n",
      "merged_data = pd.merge(location_data, sample_data)\n",
      "merged_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>POP</th>\n",
        "      <th>LAT</th>\n",
        "      <th>LONG</th>\n",
        "      <th>IND</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> CA044</td>\n",
        "      <td>-17.466667</td>\n",
        "      <td> 138.333333</td>\n",
        "      <td> CA044</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> CA045</td>\n",
        "      <td>-16.666667</td>\n",
        "      <td> 135.850000</td>\n",
        "      <td> CA045</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> CA046</td>\n",
        "      <td>-16.450000</td>\n",
        "      <td> 134.616667</td>\n",
        "      <td> CA046</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> CA047</td>\n",
        "      <td>-12.700000</td>\n",
        "      <td> 132.933333</td>\n",
        "      <td> CA047</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> CA048</td>\n",
        "      <td>-20.775000</td>\n",
        "      <td> 139.785556</td>\n",
        "      <td> CA048</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td> CA049</td>\n",
        "      <td>-14.025117</td>\n",
        "      <td> 130.770517</td>\n",
        "      <td> CA049</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td> CA050</td>\n",
        "      <td>-15.875286</td>\n",
        "      <td> 129.051271</td>\n",
        "      <td> CA050</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td> CA051</td>\n",
        "      <td>-13.790000</td>\n",
        "      <td> 133.090000</td>\n",
        "      <td> CA051</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td> CA052</td>\n",
        "      <td>-12.720000</td>\n",
        "      <td> 131.702167</td>\n",
        "      <td> CA052</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td> CA053</td>\n",
        "      <td>-14.800000</td>\n",
        "      <td> 134.945000</td>\n",
        "      <td> CA053</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th></th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>42 rows \u00d7 4 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "     POP        LAT        LONG    IND\n",
        "0  CA044 -17.466667  138.333333  CA044\n",
        "1  CA045 -16.666667  135.850000  CA045\n",
        "2  CA046 -16.450000  134.616667  CA046\n",
        "3  CA047 -12.700000  132.933333  CA047\n",
        "4  CA048 -20.775000  139.785556  CA048\n",
        "5  CA049 -14.025117  130.770517  CA049\n",
        "6  CA050 -15.875286  129.051271  CA050\n",
        "7  CA051 -13.790000  133.090000  CA051\n",
        "8  CA052 -12.720000  131.702167  CA052\n",
        "9  CA053 -14.800000  134.945000  CA053\n",
        "     ...        ...         ...    ...\n",
        "\n",
        "[42 rows x 4 columns]"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read_vcf_slow( data_file ):\n",
      "    vcf_handle = vcf.VCFReader( data_file )\n",
      "    n_processes\n",
      "    samples = vcf_handle.samples\n",
      "    samples_to_keep = [  i for i, s in enumerate( samples )     if s in merged_data[ 'IND' ].tolist()  ]\n",
      "    \n",
      "    def get_snp_allele_freq( gt ):\n",
      "        if gt[0] == '.' or gt[2] == '.':\n",
      "            return np.nan\n",
      "        return int( gt[0] ) + int( gt[2] )\n",
      "    \n",
      "    \n",
      "    n_samples = len(samples_to_keep)\n",
      "    pairs = []\n",
      "    for i in xrange( n_samples ):\n",
      "            for j in xrange( n_samples):\n",
      "                pairs.append(  ( i, j )  )\n",
      "                \n",
      "                \n",
      "    pw_comps = np.zeros( (n_samples, n_samples ) )\n",
      "    pw_diff = np.zeros( (n_samples, n_samples ) )\n",
      "    \n",
      "    p = Pool( n_processes )\n",
      "    for line,snp in enumerate(vcf_handle):\n",
      "        current_snp = [ get_snp_allele_freq( snp.genos[i][0] ) for i in samples_to_keep ]\n",
      "        \n",
      "                \n",
      "        \n",
      "        def pw_fun( pair ):\n",
      "            i, j = pair\n",
      "            valid_comparison = not np.isnan( current_snp[i] - current_snp[j] )\n",
      "            if valid_comparison:\n",
      "                pw_comps[i,j] += 1\n",
      "                pw_diff[i,j] += abs( current_snp[i] - current_snp[j] )\n",
      "        \n",
      "        #p.map( pw_fun, pairs )\n",
      "        map( pw_fun, pairs )\n",
      "        if line % 100 == 0:\n",
      "            print line\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pw_diff"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'pw_diff' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-12-f9b516ea01e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpw_diff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'pw_diff' is not defined"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "?zip"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.outer?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cyvcf\n",
      "from collections import Counter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read_vcf( data_file):\n",
      "    vcf_handle = cyvcf.Reader( open(data_file, 'r' ) )\n",
      "    samples = vcf_handle.samples\n",
      "\n",
      "    samples_to_keep =  merged_data[ 'IND' ].tolist()  \n",
      "    n_samples = len( samples_to_keep )\n",
      "    \n",
      "    c_missing = Counter()\n",
      "    c_diff1 = Counter()\n",
      "    c_diff2 = Counter()\n",
      "    \n",
      "     \n",
      "    \n",
      "    for i,line in enumerate(vcf_handle):\n",
      "        hom_ref = line.get_hom_refs()\n",
      "        hom_alt = line.get_hom_alts()\n",
      "        hets = line.get_hets()\n",
      "        no_call = line.get_unknowns()\n",
      "        \n",
      "        for s1 in hom_ref:\n",
      "            if s1.sample not in samples_to_keep: continue\n",
      "            for s2 in hets:\n",
      "                if s2.sample not in samples_to_keep: continue\n",
      "                c_diff1.update( [(s1.sample, s2.sample)] )\n",
      "            for s2 in no_call:\n",
      "                if s2.sample not in samples_to_keep: continue\n",
      "                c_missing.update( [(s1.sample, s2.sample)] )\n",
      "            for s2 in hom_alt:\n",
      "                if s2.sample not in samples_to_keep: continue\n",
      "                c_diff2.update( [(s1.sample, s2.sample)] )\n",
      "                \n",
      "        for s1 in hom_alt:\n",
      "            if s1.sample not in samples_to_keep: continue\n",
      "    \n",
      "            for s2 in hets:\n",
      "                if s2.sample not in samples_to_keep: continue\n",
      "                c_diff1.update( [(s1.sample, s2.sample)] )\n",
      "            for s2 in no_call:\n",
      "                if s2.sample not in samples_to_keep: continue\n",
      "                c_missing.update( [(s1.sample, s2.sample)] )\n",
      "        \n",
      "        for k,s1 in enumerate( no_call) :\n",
      "            if s1.sample not in samples_to_keep: continue\n",
      "    \n",
      "            for s2 in hets:\n",
      "                if s2.sample not in samples_to_keep: continue\n",
      "                c_missing.update( [(s1.sample, s2.sample)] )\n",
      "            for s2 in no_call[k+1:]:\n",
      "                if s2.sample not in samples_to_keep: continue\n",
      "                c_missing.update( [(s1.sample, s2.sample)] )     \n",
      "                \n",
      "        for k,s1 in enumerate(hets):\n",
      "            if s1.sample not in samples_to_keep: continue\n",
      "    \n",
      "            for s2 in hets:\n",
      "                if s2.sample not in samples_to_keep: continue\n",
      "                c_diff1.update( [(s1.sample, s2.sample)] )\n",
      "        \n",
      "        \n",
      "        if i % 10000 == 0:\n",
      "            print i\n",
      "            \n",
      "    \n",
      "    n_snp = i\n",
      "    \n",
      "    pw_dist = np.zeros( (n_samples, n_samples) )\n",
      "\n",
      "    for i, s1 in enumerate( samples_to_keep ):\n",
      "        for j, s2 in enumerate( samples_to_keep) :\n",
      "            pw_dist[i, j] = 2 *c_diff2[s1, s2] + 2 * c_diff2[s2, s1]\n",
      "            pw_dist[i, j] += c_diff1[s1,s2] + c_diff1[s2, s1]\n",
      "            pw_dist[i, j] /= ( n_snp - c_missing[s1, s2] - c_missing[s2, s1] ) \n",
      "    \n",
      "    return( pw_dist, ( n_samples, n_snp )  )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pw_dist, n_samp_snp = read_vcf(data_file)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "10000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "20000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "30000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "40000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "50000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "60000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pw_dist.shape\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'name' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-33-77801b744e0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpw_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmerged_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.coord'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LAT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LONG'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'name' is not defined"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At this point we have all the data we need for eems to run: the vcf can be made from the pw dist matrix, the "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def write_eems_input_files( name='eems'):\n",
      "    np.savetxt(name+'.diffs', pw_dist )\n",
      "    merged_data.to_csv(name+'.coord', sep=' ', header=False, cols=['LAT', 'LONG'], index=False)\n",
      "\n",
      "    with open( name + '.dimns', 'w' ) as settings_file:\n",
      "        settings_file.write( \"%f %f\\n\"%(  ( min(merged_data['LAT']), max(merged_data['LAT']) )  ) )\n",
      "        settings_file.write( \"%f %f\\n\"%(  ( min(merged_data['LONG']), max(merged_data['LONG']) )  ) )\n",
      "        settings_file.write( \"%f %f\\n\"%(  n_samp_snp  ) )\n",
      "                            \n",
      "                            \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "write_eems_input_files('test')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "(-20.774999999999999, -11.57, 123.75, 139.78555600000001)"
       ]
      }
     ],
     "prompt_number": 48
    }
   ],
   "metadata": {}
  }
 ]
}